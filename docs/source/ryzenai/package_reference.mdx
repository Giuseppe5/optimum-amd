<!--Copyright 2023 The HuggingFace Team. All rights reserved.
Licensed under the MIT License.
-->

## RyzenAIModel

[[autodoc]] ryzenai.RyzenAIModel
    - from_pretrained
    - save_pretrained
    - reshape

[[autodoc]] ryzenai.RyzenAIModelForImageClassification

[[autodoc]] ryzenai.RyzenAIModelForImageSegmentation

[[autodoc]] ryzenai.RyzenAIModelForImageToImage

[[autodoc]] ryzenai.RyzenAIModelForObjectDetection

[[autodoc]] ryzenai.RyzenAIModelForCustomTasks

## Configuration

[[autodoc]] ryzenai.RyzenAIConfig

## Quantization

Ryzen AI IPU best performances are achieved using [quantized models](https://huggingface.co/docs/optimum/concept_guides/quantization). There are two different ways to quantize models for Ryzen AI IPU: through [Vitis AI Quantizer](https://docs.xilinx.com/r/en-US/ug1414-vitis-ai/Vitis-AI-Quantizer), used in Optimum's `RyzenAIOnnxQuantizer`, and through [Brevitas](https://github.com/Xilinx/brevitas) library, used in Optimum's `BrevitasQuantizer`.

`RyzenAIOnnxQuantizer` is recommended to quantize [timm](https://github.com/huggingface/pytorch-image-models) models, while `BrevitasQuantizer` is recommended to quantize other models.

### Using Vitis AI Quantizer

[[autodoc]] ryzenai.RyzenAIOnnxQuantizer

[[autodoc]] ryzenai.QuantizationConfig

### Using Brevitas

[[autodoc]] brevitas.BrevitasQuantizer

[[autodoc]] brevitas.BrevitasQuantizationConfig
